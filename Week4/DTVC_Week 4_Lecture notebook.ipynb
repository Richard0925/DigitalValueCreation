{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffa4b72",
   "metadata": {},
   "source": [
    "# Social Media APIs and Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e39491",
   "metadata": {},
   "source": [
    "## 1. Google trends to predict Covid cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289fd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cf5eb",
   "metadata": {},
   "source": [
    "*Google Flu Trends* was a web service operated by Google. It provided estimates of influenza activity for more than 25 countries. By aggregating Google Search queries, it attempted to make accurate predictions about flu activity. This project was first launched in 2008 by *Google.org* to help predict outbreaks of flu. *Google Flu Trends* stopped publishing current estimates on 9 August 2015. We can use the open access tool *Google Trends* to build a similar engine that can predict the daily number of Covid cases. Here, we take a first step, by identifying patterns between searches and cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d8370",
   "metadata": {},
   "source": [
    "**Loading a data set of daily Covid cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a8f80",
   "metadata": {},
   "source": [
    "We start by analyzing daily Covid data with Google trends. Before getting into the Google API, we take data about daily cases from \"Our World in Data\", which is freely available <a href='https://github.com/owid/covid-19-data/tree/master/public/data'>here</a> (the site also recommends the below stable link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2dc2dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1346'>1347</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1347'>1348</a>\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1348'>1349</a>\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1349'>1350</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1280'>1281</a>\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1281'>1282</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1326'>1327</a>\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1327'>1328</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1275'>1276</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1276'>1277</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1035'>1036</a>\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1036'>1037</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1038'>1039</a>\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1039'>1040</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1040'>1041</a>\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=973'>974</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=974'>975</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=975'>976</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1451'>1452</a>\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1453'>1454</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py?line=1454'>1455</a>\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:512\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=505'>506</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=506'>507</a>\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=507'>508</a>\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=508'>509</a>\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=509'>510</a>\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=510'>511</a>\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=511'>512</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=512'>513</a>\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=513'>514</a>\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=514'>515</a>\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=515'>516</a>\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=516'>517</a>\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=517'>518</a>\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=518'>519</a>\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=519'>520</a>\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1070\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=1068'>1069</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=1069'>1070</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=1070'>1071</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1341\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=1339'>1340</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=1340'>1341</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py?line=1341'>1342</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://covid.ourworldindata.org/data/owid-covid-data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=208'>209</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=209'>210</a>\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=210'>211</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=311'>312</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=312'>313</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=313'>314</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=314'>315</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=315'>316</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py?line=316'>317</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=934'>935</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=935'>936</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=936'>937</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=945'>946</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=946'>947</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=947'>948</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=949'>950</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=601'>602</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=603'>604</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=604'>605</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=606'>607</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=607'>608</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1438'>1439</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1440'>1441</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1441'>1442</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1726'>1727</a>\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1727'>1728</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1728'>1729</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1729'>1730</a>\u001b[0m     f,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1730'>1731</a>\u001b[0m     mode,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1731'>1732</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1732'>1733</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1733'>1734</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1734'>1735</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1735'>1736</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1736'>1737</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1737'>1738</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1738'>1739</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1739'>1740</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:714\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=710'>711</a>\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=712'>713</a>\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=713'>714</a>\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=714'>715</a>\u001b[0m     path_or_buf,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=715'>716</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=716'>717</a>\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=717'>718</a>\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=718'>719</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=719'>720</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=721'>722</a>\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=722'>723</a>\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:364\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=361'>362</a>\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=362'>363</a>\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=363'>364</a>\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=364'>365</a>\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=365'>366</a>\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=366'>367</a>\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:266\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=259'>260</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=260'>261</a>\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=261'>262</a>\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=262'>263</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=263'>264</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py?line=265'>266</a>\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=213'>214</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=214'>215</a>\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=215'>216</a>\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=515'>516</a>\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=517'>518</a>\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=518'>519</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=520'>521</a>\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=521'>522</a>\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=532'>533</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=534'>535</a>\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=535'>536</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=536'>537</a>\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=537'>538</a>\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=538'>539</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=493'>494</a>\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=494'>495</a>\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=495'>496</a>\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=496'>497</a>\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=497'>498</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1390'>1391</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1391'>1392</a>\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1347'>1348</a>\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1348'>1349</a>\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1349'>1350</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1350'>1351</a>\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1351'>1352</a>\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py?line=1352'>1353</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)>"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\n",
    "df.fillna(0,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97281b5d",
   "metadata": {},
   "source": [
    "As always when working with dates, we want to make sure that our data is actually recognized as such (and not just a string), so we convert the `date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778be1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6e649",
   "metadata": {},
   "source": [
    "Let's start with a specific location and time: Covid cases in the US between April 1, 2020, and December 1, 2020 (some more on the choice of date later). Therefore, continue by creating a new dataframe containing only the relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = df[(df['date'] <= datetime(2020,12,1)) & (df['date'] >= datetime(2020,4,1)) & (df['iso_code'] == 'USA')]\n",
    "us_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ed965",
   "metadata": {},
   "source": [
    "**Using Google Trends to find out about searches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361980d6",
   "metadata": {},
   "source": [
    "`pytrend`'s `TrendReq` connects us directly with the Google Trend API. We use `build_payload` to establish what we are looking for (keywords, location, timeframe, etc.), and can then call up different data, such as interest over time, interest by region, related topics, related queries, trending searches, top charts, suggestions, or categories. The full documentation is <a href=\"https://github.com/GeneralMills/pytrends\">here</a>.\n",
    "\n",
    "Let's start by getting `interest_over_time()` for the search \"can't smell\" during the same time frame as above. Note that, if you specify a time frame longer than 270 days, the API will return weekly results instead of daily ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrend = TrendReq()\n",
    "pytrend.build_payload(kw_list = [\"can't smell\"],timeframe='2020-04-01 2020-12-01', geo=\"US\")\n",
    "smell_trends = pytrend.interest_over_time()\n",
    "smell_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec1bb9",
   "metadata": {},
   "source": [
    "Note that `interest_over_time()` already generates a data frame. However, this is indexed by date, which can make merging a bit tricky. So instead of using that data frame, we create a new one with the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_trends = pd.DataFrame(data = {'date': smell_trends.index.tolist(), 'search': smell_trends[\"can't smell\"].tolist()})\n",
    "smell_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b2f11",
   "metadata": {},
   "source": [
    "Let's now take a look at the searches over time. Note that the \"interest\" returned by our query is relative to the peak interest within the query timeframe (so the maximum will always be 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot( x = 'date',\n",
    "             y = 'search',\n",
    "             data = smell_trends,\n",
    "             label = 'daily hits', color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e697bb4",
   "metadata": {},
   "source": [
    "To get a better idea of what is happening, let's add a rolling weekly average (we can use `column.rolling(k)` where `k` is the number of entries). Note that this creates some `NA` values, because there is no rolling average for the first 6 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_trends['rolling_avg' ] = smell_trends.search.rolling(7).mean()\n",
    "smell_trends = smell_trends.fillna(0)\n",
    "sns.scatterplot( x = 'date',\n",
    "             y = 'search',\n",
    "             data = smell_trends,\n",
    "             label = 'daily hits', color=\"blue\")\n",
    "sns.lineplot( x = 'date',\n",
    "             y = 'rolling_avg',\n",
    "             data = smell_trends,\n",
    "             label = 'rolling_avg', color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a16ff8",
   "metadata": {},
   "source": [
    "In order to run a linear regression, all the data needs to be in a single dataframe. Consequently, we need to combine the Google trends data with the Covid data. This can be done seamlessly by merging the two dataframes into a new one using the command `.merge()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b04588",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(us_df,smell_trends,on=\"date\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d9f7f0",
   "metadata": {},
   "source": [
    "**Combining cases and searches graphically**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6b0eca",
   "metadata": {},
   "source": [
    "Next, we plot the two time series together, to see if we can spot a pattern. Note that the scales are vastly different, so it pays off to create a graph with multiple scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6651017",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=combined_df.date, y=combined_df.new_cases, color = \"red\")\n",
    "ax.set_ylabel(\"cases\",color=\"red\",fontsize=14)\n",
    "ax2 = plt.twinx()\n",
    "sns.scatterplot(x=combined_df.date, y=combined_df.search, color = \"blue\")\n",
    "ax2.set_ylabel(\"search\",color=\"blue\",fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010a0e8",
   "metadata": {},
   "source": [
    "**Estimating the relationship between searches and cases**\n",
    "\n",
    "We can start with a simple regression of the daily cases on the searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(combined_df.search)\n",
    "model = sm.OLS(combined_df.new_cases, X)\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d06f2e8",
   "metadata": {},
   "source": [
    "We can probably find a better model than that. For example, there is a lot of noise, so we may want to smooth out the data. Let's try using the rolling weekly average of cases that we added in before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fbe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(combined_df.rolling_avg)\n",
    "model = sm.OLS(combined_df.new_cases, X)\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956eef7f",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Try increasing the predictive power of this method even further. There could be a lag between intial symptoms and an eventual test - we can created lagged variables using `column.shift(k)` where `k` is the number of observations by which the column is shifted downward (e.g., if `k=7`, the \"search\" data from day 1 is now in the new column at day 8). Of course, there are no values to shift in anywhere before observation `k`, so don't forget to deal with `NA` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93805b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['shifted_1_week'] = combined_df.search.shift(7)\n",
    "combined_df['shifted_2_weeks'] = combined_df.search.shift(14)\n",
    "combined_df['shifted_3_weeks'] = combined_df.search.shift(21)\n",
    "combined_df = combined_df.fillna(0)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aaefd4",
   "metadata": {},
   "source": [
    "Run the model with the right columns for the `X` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a58d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(combined_df[['rolling_avg','shifted_1_week','shifted_2_weeks','shifted_3_weeks']])\n",
    "model = sm.OLS(combined_df.new_cases, X)\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42448c1c",
   "metadata": {},
   "source": [
    "What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee357f",
   "metadata": {},
   "source": [
    "### Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef5f0a",
   "metadata": {},
   "source": [
    "Let's explore another country: check both of the search terms \"smell\" and \"fever\" for the United Kingdom (`geo=\"GB\"`), for the timeframe January 1, 2020 to May 1, 2020 (`'2020-01-01 2020-05-01'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrend = TrendReq()\n",
    "pytrend.build_payload(kw_list = [\"smell\",\"fever\"],timeframe='2020-01-01 2020-05-01', geo=\"GB\")\n",
    "trends = pytrend.interest_over_time()\n",
    "trends = pd.DataFrame(data = {'date': trends.index.tolist(),\n",
    "                              'search_smell': trends[\"smell\"].tolist(),\n",
    "                              'search_fever': trends[\"fever\"].tolist()})\n",
    "trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e55da1",
   "metadata": {},
   "source": [
    "Try to plot the patterns of both columns in a single plot (e.g., using `seaborn`). What about differences do you see in those patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef41e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot( x = 'date',\n",
    "                 y = 'search_smell',\n",
    "                 data = trends,\n",
    "                 label = 'daily hits smell')\n",
    "sns.scatterplot( x = 'date',\n",
    "                 y = 'search_fever',\n",
    "                 data = trends,\n",
    "                 label = 'daily hits fever')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d91eee",
   "metadata": {},
   "source": [
    "### Discussion point: what could this type of data be helpful for in a buisness setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4592bee",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104d8b7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ca6d9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5427f23",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166737e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaedf41",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6592c4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b96ca",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a11eb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48efc519",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611e4dd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d6ce6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ddeca",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38c0b6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c18890",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf7a1e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5fe73",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9e030",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e9437",
   "metadata": {},
   "source": [
    "## 2. Measuring engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4e4dc",
   "metadata": {},
   "source": [
    "Let's use our newfound skills with the Google trends API to measure enagagement following a marketing campaign. The company Red Bull spends a large sum of money on its Formula 1 team, in order to market its brand. But it also does lots of other marketing activities. Because most people don't go to the supermarket to buy a Red Bull drink after watching a Formula 1 event, it can be quite tricky to associate sales with different marketing campaigns. But social media allows us to capture consumer reactions and engagement in real time! So if we know that consumer engagement leads to more sales (at least, on the long term), it can be extremely valuable to measure engagement following marketing campaigns.\n",
    "\n",
    "Our question will be twofold:\n",
    "1. Does Red Bull create engagement with its Formula 1 expenditures?\n",
    "2. Does the Pilot matter? I.e., is engagement related to success?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91744533",
   "metadata": {},
   "source": [
    "We start by pulling Google trends data for the search term \"red bull\" between March and yesterday (the Formula 1 season started at the end of March)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrend = TrendReq()\n",
    "pytrend.build_payload(kw_list = [\"red bull\"],timeframe='2022-03-01 2022-10-13')\n",
    "trends = pytrend.interest_over_time()\n",
    "trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90998d6",
   "metadata": {},
   "source": [
    "Note: Google Trends only gives us data about searches up to approx. three days ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629187d0",
   "metadata": {},
   "source": [
    "As before, we want to clean up the dataset a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trendsdf = pd.DataFrame(data = {'date': trends.index.tolist(),\n",
    "                                'search': trends[\"red bull\"].tolist()})\n",
    "trendsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97aad92",
   "metadata": {},
   "source": [
    "Don't forget to convert the date string to an actual Date object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trendsdf['date'] = pd.to_datetime(trendsdf['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f969313",
   "metadata": {},
   "source": [
    "Next, we take a look at the daily search hits (recall that the maximum will always be 100 in any Google Trends query):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84c372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot( x = 'date',\n",
    "             y = 'search',\n",
    "             data = trendsdf,\n",
    "             label = 'daily hits', color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb7cd6",
   "metadata": {},
   "source": [
    "We have some data on the searches. Now, we can add race data into the mix (you can find the csv on Moodle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf = pd.read_csv('red_bull_race_results.csv')\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e965d",
   "metadata": {},
   "source": [
    "The dataset gives the positioning of the two Red Bull pilots, Sergio Pérez and Max Verstappen. A missing value indicates that the pilot did not finish the race.\n",
    "\n",
    "Make sure that our dates are actual dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf['date'] = pd.to_datetime(racingdf['date'], format=\"%d.%m.%y\")\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62d7d3",
   "metadata": {},
   "source": [
    "Similar to before, we can merge the two data frames by date, in order to understand whether race day implies a high number of searches. For simplicity, we can take only one extra column of `racingdf`, to see whether the date exists or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(trendsdf, racingdf[['date','perez']], how='left',on='date')\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9114132",
   "metadata": {},
   "source": [
    "Whereever there is a missing value in the `perez` column, there was no race on the day. We can adjust our dataframe accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['raceday'] = temp['perez'].notna()\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7be28c",
   "metadata": {},
   "source": [
    "It's time to plot our merged result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97777415",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot( x = 'date',\n",
    "             y = 'search',\n",
    "             data = temp,\n",
    "            hue=\"raceday\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857074d3",
   "metadata": {},
   "source": [
    "A first look at the data seems to indicate that there is support for the hypothesis that the Formula 1 marketing leads to customer engagement. Of course, more work is needed to establish robust evidence.\n",
    "\n",
    "However, we will turn to the second question instead (whether the pilots matter). For this, we need to first clean the racing dataset.\n",
    "\n",
    "Since disqualification is often a topic of intense interest in Formula 1, we create an additional column to measure whether a driver has not completed the race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7a751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "racingdf['perez_out'] = racingdf['perez'].isna().astype(int)\n",
    "racingdf['verstappen_out'] = racingdf['verstappen'].isna().astype(int)\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b1fd3",
   "metadata": {},
   "source": [
    "There is one special case, which requires contextual knowledge: on 2022-03-20, both drivers did not finish the race and were only placed because they had completed more than 90%. For consistency, we may consider putting a 1 in the column `'perez_out'` and in the column `'verstappen_out'` here (this is a typical case in which you want to check for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf.loc[racingdf['date'] == '2022-03-20','perez_out'] = 1\n",
    "racingdf.loc[racingdf['date'] == '2022-03-20','verstappen_out'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28840923",
   "metadata": {},
   "source": [
    "We then remove the `NAs` by replacing them with the worst result (this is of course just one possible choice and requires further analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c02428",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf['perez'] = racingdf['perez'].fillna(racingdf['perez'].max())\n",
    "racingdf['verstappen'] = racingdf['verstappen'].fillna(racingdf['verstappen'].max())\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf40080",
   "metadata": {},
   "source": [
    "Next, we want to find out the search results around the race days. We start with an example, by taking the first race day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57af81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_date = racingdf.loc[0,'date']\n",
    "race_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d9a74",
   "metadata": {},
   "source": [
    "We now define a time difference, between the race date and the date of searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71579ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trendsdf['difftime'] = trendsdf['date']-race_date\n",
    "trendsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae50ff",
   "metadata": {},
   "source": [
    "We want this time difference to be in days, but as a number. For this, we use the `.days` attribute of the time difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trendsdf['difftime'] = [diff.days for diff in trendsdf['difftime']]\n",
    "trendsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65ace7",
   "metadata": {},
   "source": [
    "Finally, we want to focus on the trends results 3 days before and after the race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "racetrends = trendsdf[abs(trendsdf['difftime']) <= 3]\n",
    "racetrends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4313b",
   "metadata": {},
   "source": [
    "Because overall trends may vary all the time for a number of factors, we focus on measuring the race day searches compared to the average search number in the week around the race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(racetrends['search'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5c48c",
   "metadata": {},
   "source": [
    "We will create an `\"engagement\"` score by relating the race day score to the minimum score during the week surrounding the race day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "racetrends[racetrends['difftime']==0].iloc[0]['search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "racetrends[racetrends['difftime']==0].iloc[0]['search']/np.mean(racetrends['search'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b7d42",
   "metadata": {},
   "source": [
    "Let's put it all together.  In particular, we go through all the race dates and find the engagement level as specified above on the relevant date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda31304",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_engagement = []\n",
    "for i in range(len(racingdf)):\n",
    "    race_date = racingdf.iloc[i,]['date'] # Get the current race date\n",
    "    trendsdf['difftime'] = trendsdf['date']-race_date # Get the difference between the trends-df dates and the current racedate\n",
    "    trendsdf['difftime'] = [diff.days for diff in trendsdf['difftime']] # Convert this difference to days\n",
    "    racetrends = trendsdf[abs(trendsdf['difftime']) <= 3] # If the difference (in days) is less than or equal to three, consider the trends on this day for comparison\n",
    "    if len(racetrends[racetrends['difftime']==0]) > 0: # On the actual race day, measure the engagememt relative to the average engagement in the week around the raceday\n",
    "            relative_engagement.append( racetrends[racetrends['difftime']==0].iloc[0]['search']/np.mean(racetrends['search']))\n",
    "    else:\n",
    "        relative_engagement.append(np.nan)\n",
    "racingdf['engagement'] = relative_engagement\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc718dd7",
   "metadata": {},
   "source": [
    "Now that we have the data, we can try to see what effects the placements have on engagement. Of course, we also analyze the effect of a driver not finishing the race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ee555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = racingdf.drop(['date', 'engagement'], axis=1)\n",
    "Y = racingdf.engagement\n",
    "X = sm.add_constant(X)\n",
    "lm = sm.OLS(Y,X).fit()\n",
    "print (lm.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d894f",
   "metadata": {},
   "source": [
    "### Discussion point: Can you interpret these results? What do they indicate in terms of our second question? Why are the effect sizes different for the different drivers?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286272e1",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd843f7",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd0e28",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9a427",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04ee5d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a690d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8852a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe260c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3. Interlude: Using Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653de47",
   "metadata": {},
   "source": [
    "It might be useful to also see what users are tweeting about regarding the races. Let's take a look at the Twitter API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f922d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7a828",
   "metadata": {},
   "source": [
    "With the Twitter API we can access most of Twitter’s functionality from within Python (that means both reading **and** writing Tweets, or finding out about users and trends). The package of choice is *Tweepy*, which deals with all the messy details.\n",
    "\n",
    "To access the Twitter API, you need to be authenticated. Hence, every request has to come with authentication information. To get this information in the first place, we need to generate our own credentials with a Developer Account:\n",
    "\n",
    "1. Go to the <a href=https://developer.twitter.com/en>Twitter Developer Site</a> and apply for a Developer Account (you will need a Twitter account for this).\n",
    "2. Create an application (e.g., \"My_first_application\"). Credentials and limits are per application, not per account.\n",
    "3. Once you have created your application, you can transfer your consumer API key and secret, as well as your app access key and secret to the Python code below (see also https://developer.twitter.com/en/docs/basics/authentication/overview/oauth)\n",
    "\n",
    "You can directly add your data as a string like this:\n",
    "```\n",
    "CONSUMER_API_KEY = 'COPY STRING HERE'\n",
    "CONSUMER_API_SECRET = 'COPY STRING HERE'\n",
    "ACCESS_KEY = 'COPY STRING HERE'\n",
    "ACCESS_SECRET = 'COPY STRING HERE'\n",
    "```\n",
    "\n",
    "So that I can share my code without everyone using my credentials (which would probably lead to me being blocked by Twitter), I'm instead reading the data from a csv here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_access = pd.read_csv('API_access.csv',delimiter=';')\n",
    "CONSUMER_API_KEY = api_access[api_access['api'] == 'twitter_consumer_api_key']['key'].tolist()[0]\n",
    "CONSUMER_API_SECRET = api_access[api_access['api'] == 'twitter_consumer_api_secret']['key'].tolist()[0]\n",
    "ACCESS_KEY = api_access[api_access['api'] == 'twitter_access_key']['key'].tolist()[0]\n",
    "ACCESS_SECRET = api_access[api_access['api'] == 'twitter_access_secret']['key'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b868c",
   "metadata": {},
   "source": [
    "We are also not allowed to request too many Tweets at the same time. There are per-day limits, as well as \"rate limits\" for 15-minute blocks. If you exceed your limits, you **will** get blocked for some time. For detailed information on the limits, check out https://developer.twitter.com/en/docs/rate-limits.\n",
    "In many cases, we can use the functionality of Tweepy to automatically delay calls in order to wait on the rate limit - but be aware that this doesn't always work, and we may need to manually add timeouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb87e1",
   "metadata": {},
   "source": [
    "We are now ready to create our verified interface (automatically waiting on our rate limit as necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_API_KEY, CONSUMER_API_SECRET)\n",
    "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060fbf9",
   "metadata": {},
   "source": [
    "Let's download some tweets!\n",
    "We actually have different APIs to choose from. An overview can be found here: https://docs.tweepy.org/en/stable/api.html\n",
    "\n",
    "We will use the standard search API. Note that the API only allows you to download tweets based on general queries from the past week. If you want to download older tweets, you will need to dowload the tweets of a particular account (see below), or use the 30-day API, for example.\n",
    "\n",
    "We can make a simple query such as `q=\"bayes\"`. However, can you see why this could lead to problems?\n",
    "\n",
    "Luckily, we can simply combine keywords with `OR` and `AND`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.search_tweets,q=\"bayes AND business AND school\",lang=\"en\").items():\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396c743",
   "metadata": {},
   "source": [
    "Here, `lang` specifies the language of tweets we request. Let's take a look at our tweets, as well as some of the basic information about them. You can find details about the tweet objects at https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc51190",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    print(\"Created at: \" + str(tweet.created_at))\n",
    "    print(\"User: \" + tweet.user.screen_name)\n",
    "    print(\"Followers: \" + str(tweet.user.followers_count))\n",
    "    print(\"Content: \" + tweet.text)\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b2a99",
   "metadata": {},
   "source": [
    "Note that there are some tweets starting with \"RT\". These are retweets, and can easily be filtered out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ac26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search_tweets,q=\"bayes AND business AND school AND -filter:retweets\",lang=\"en\").items():\n",
    "    print(\"Created at: \" + str(tweet.created_at))\n",
    "    print(\"User: \" + tweet.user.screen_name)\n",
    "    print(\"Followers: \" + str(tweet.user.followers_count))\n",
    "    print(\"Content: \" + tweet.text)\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185fb9b6",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Repeat the query above, searching for tweets with the hashtag #bayes without any other limitations, and print out the key information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fad35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.search_tweets,q=\"#bayes\").items():\n",
    "    tweets.append(tweet)\n",
    "    \n",
    "for tweet in tweets:\n",
    "    print(\"Created at: \" + str(tweet.created_at))\n",
    "    print(\"User: \" + tweet.user.screen_name)\n",
    "    print(\"Followers: \" + str(tweet.user.followers_count))\n",
    "    print(\"Content: \" + tweet.text)\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef237a53",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcefc59",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9575e9e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91f376",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75dd7c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279bd145",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731b21f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9dac6",
   "metadata": {},
   "source": [
    "## 4. Finding Red bull tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5644f",
   "metadata": {},
   "source": [
    "Let's go back to Red Bull, and search for tweets with the hash tag `\"#redbull\"` (omitting retweets and sticking with English-language ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9759cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.search_tweets,q=\"#redbull -filter:retweets\",lang=\"en\").items():\n",
    "    tweets.append(tweet)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa37c10",
   "metadata": {},
   "source": [
    "A side note: When requesting tweets in this manner, the API will sometimes return truncated versions of tweets. That means, even if we search for tweets with #redbull, the tweet we receive may not contain the hashtag. We can check whether a Tweet is truncated with `.truncated`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92931bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([tweets[i].truncated for i in range(len(tweets))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcb4a0",
   "metadata": {},
   "source": [
    "If we need full tweets, we can\n",
    "- \"Hydrate\" tweets at any time, using just their ID (i.e. request the full text). You can thus use only the tweet ID to share your data. The relevant API call is `api.get_status(id)`.\n",
    "- add the parameter `tweet_mode='extended'` to our `tweepy.Cursor()` call. In this case, returned tweets no longer have a `.text` attribute, but a `.full_text` attribute "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f4a6d",
   "metadata": {},
   "source": [
    "Let's start having a look at Tweeter demographics. Where are tweeters from (we only consider accounts with locations)? Remember, that the <a href=\"https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet\">Developer Platform</a> has all the relevant information about tweet objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe633f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[0]\n",
    "tweet.user.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ece748",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_loc = [tweet.user.location for tweet in tweets if tweet.user.location != \"\"]\n",
    "len(tweet_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b74444",
   "metadata": {},
   "source": [
    "We will consider only locations that have at least 5 tweets emerging from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6795c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_loc_df = pd.DataFrame(tweet_loc,columns=['location'])\n",
    "tweet_loc_df = tweet_loc_df.groupby('location')['location'].count().reset_index(name='count')\n",
    "tweet_loc_df = tweet_loc_df[tweet_loc_df['count'] >= 5]\n",
    "tweet_loc_df.sort_values(by='count',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615a5c6",
   "metadata": {},
   "source": [
    "Do you see a possible problem here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eece30",
   "metadata": {},
   "source": [
    "Let's now take a look at when the Tweets where sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.created_at.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.created_at.date().day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed57dc",
   "metadata": {},
   "source": [
    "We can collect the counts per day into a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a30377",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_day = [tweet.created_at.date().day for tweet in tweets]\n",
    "tweet_day_df = pd.DataFrame(tweet_day,columns=['day'])\n",
    "tweet_day_df = tweet_day_df.groupby('day')['day'].count().reset_index(name='count')\n",
    "tweet_day_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784b796",
   "metadata": {},
   "source": [
    "Let's see this graphically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(y=tweet_day_df['count'], x = tweet_day_df['day'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb74cd",
   "metadata": {},
   "source": [
    "The variation seems familiar, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122e951",
   "metadata": {},
   "source": [
    "We now want to learn more about the people (and company accounts) that follow Red Bull (as well as about whom they follow other than Red Bull). Let's start with finding some of Red Bull's followers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd70d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_rb = []\n",
    "for follower in tweepy.Cursor(api.get_followers,screen_name=\"redbull\").items(5):\n",
    "    followers_rb.append(follower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef84be9",
   "metadata": {},
   "source": [
    "A company like Red Bull has quite some followers and we would run into problems trying to get all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213d0a7",
   "metadata": {},
   "source": [
    "Note that followers are saved as \"User\" objects, with their very own attributes, found here: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user. The twitter-handle is defined by the `screen_name` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower = followers_rb[1]\n",
    "follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower.screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6615a1e",
   "metadata": {},
   "source": [
    "Can we get other accounts that this person follows? (Twitter defines those as friends). Sometimes, the information is set to private, so we don't know who the person is following. Hence, we need to do some Exception management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9489e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for user in tweepy.Cursor(api.get_friends, screen_name=follower.screen_name).items(10):\n",
    "        print(user.screen_name)\n",
    "except:\n",
    "    print(\"Follower \" + follower.screen_name + \" does not provide access to their friends.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b0630",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "Let's combine this for multiple of Red Bull's followers. For the first 5 followers, let's get up 10 of the accounts that they follow each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_followers_friends = []\n",
    "for follower in followers_rb:\n",
    "    followers_friends = []\n",
    "    try:\n",
    "        for user in tweepy.Cursor(api.get_friends, screen_name=follower.screen_name).items(10):\n",
    "            followers_friends.append(user)\n",
    "    except:\n",
    "        print(\"Follower \" + follower.screen_name + \" does not provide access to their friends.\")\n",
    "    print(\"Added \" + str(len(followers_friends)) + \" friends of follower \" + follower.screen_name)\n",
    "    all_followers_friends.append(followers_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5b9a8",
   "metadata": {},
   "source": [
    "It's easy to imagine how we could create a network of accounts, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d931a88",
   "metadata": {},
   "source": [
    "We can also take a look at all the Tweets of Red Bull itself. When looking at an account's Tweets, we do not have to worry about date limits (but there are still restrictions, so let's make sure not to pull too many)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rb = []\n",
    "for tweet in tweepy.Cursor(api.user_timeline,screen_name='redbull').items(1000):\n",
    "    tweets_rb.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rb[0].created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0056463",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rb[999].created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85fc880",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd73e504",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec802f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791203b5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec159b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b13ffa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758a92a",
   "metadata": {},
   "source": [
    "## 5. Back to our engagement measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6086d3",
   "metadata": {},
   "source": [
    "Let's try to enrich our `racingdf` using Tweet data. This may help us to answer the second question: What is the role of the pilot?\n",
    "\n",
    "We can only collect tweets by hashtag for a week. Hence, I have prepared previous tweets for the last year (see on Moodle). This is stored as a `pickle` file - a system that allows to directly save arbitrary Python objects outside of our program. Once we call up the pickle file, we get back exactly the variables we saved into it. Since I saved a list of tweets, the return value from `pickle.load(file)` will be a list of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ac547",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('red_bull_tweets.txt', 'rb') as file:\n",
    "    tweets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fe8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7af29",
   "metadata": {},
   "source": [
    "Note: this contains tweets (without retweets) for all the race days in the '\"red_bull_race_results.csv\"' file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f51bd",
   "metadata": {},
   "source": [
    "Briefly recall / recreate our dataset `racingdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d32344",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf = pd.read_csv('red_bull_race_results.csv')\n",
    "\n",
    "# Date formatting\n",
    "racingdf['date'] = pd.to_datetime(racingdf['date'], format=\"%d.%m.%y\")\n",
    "\n",
    "# \"out\"-indicator (adjusted on March 20)\n",
    "racingdf['perez_out'] = racingdf['perez'].isna().astype(int)\n",
    "racingdf['verstappen_out'] = racingdf['verstappen'].isna().astype(int)\n",
    "racingdf.loc[racingdf['date'] == '2022-03-20','perez_out'] = 1\n",
    "racingdf.loc[racingdf['date'] == '2022-03-20','verstappen_out'] = 1\n",
    "\n",
    "# Input placement for \"out\" days\n",
    "racingdf['perez'] = racingdf['perez'].fillna(racingdf['perez'].max())\n",
    "racingdf['verstappen'] = racingdf['verstappen'].fillna(racingdf['verstappen'].max())\n",
    "\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88353224",
   "metadata": {},
   "source": [
    "Let's take the first of these race dates and try to assign the corresponding tweets. Note that we need to convert the Twitter-specific time format into the same time format we've been using for our dates in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "racedate = racingdf['date'].iloc[0]\n",
    "print(\"Date: \" +  str(racedate))\n",
    "raceday_tweets = [tweet for tweet in tweets if pd.to_datetime(tweet.created_at.date()) == racedate]\n",
    "print(\"Total tweets: \" + str(len(raceday_tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23952c4",
   "metadata": {},
   "source": [
    "Let's take a look at one of those tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raceday_tweets[11].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8365831",
   "metadata": {},
   "source": [
    "The name \"Verstappen\" appears in here. We can, of course, check this automatically with Python (note that we use `.lower()` to avoid issues when comparing different capitalization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df05ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "'verstappen' in raceday_tweets[11].text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69642c4e",
   "metadata": {},
   "source": [
    "We can combine the above code to create three new \"engagement\" columns: a total count of tweets on raceday, a count of tweets talking about Perez and a count of tweets talking about Verstappen, all relative to the count of tweets in the week around the race. We first create an empty column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf['tweets_total'] = 0\n",
    "racingdf['tweets_perez'] = 0\n",
    "racingdf['tweets_verstappen'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f5ebe",
   "metadata": {},
   "source": [
    "In order to create our relative metric, we again go through each racedate, and search for the relevant tweets in the week around there. To be more accurate when attributing tweets to Perez/Verstappen, we search both for last and first names.\n",
    "\n",
    "Keep in mind that this is only an initial proxy measure for engagement. And note that the code will run for a bit (runtime could be much improved - do you know how? We are not doing that here, to make clearer what the code is actually doing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50efcd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dates = [pd.to_datetime(tweet.created_at.date()) for tweet in tweets] # We get a list of all tweet dates, so we don't have to recalculate them later\n",
    "for racedate in racingdf['date']:\n",
    "    perez_count_day = 0\n",
    "    perez_count_week = 0\n",
    "    verstappen_count_day = 0\n",
    "    verstappen_count_week = 0\n",
    "    total_count_day = 0\n",
    "    total_count_week = 0\n",
    "    for i in range(len(tweets)):\n",
    "        tweet_text = tweets[i].text.lower()\n",
    "        if tweet_dates[i] == racedate:\n",
    "            total_count_day += 1\n",
    "            if 'sergio' in tweet_text or 'perez' in tweet_text:\n",
    "                perez_count_day += 1\n",
    "            if 'max' in tweet_text or 'verstappen' in tweet_text:\n",
    "                verstappen_count_day += 1\n",
    "        if abs((tweet_dates[i] - racedate).days) <= 3:\n",
    "            total_count_week += 1\n",
    "            if 'sergio' in tweet_text or 'perez' in tweet_text:\n",
    "                perez_count_week += 1\n",
    "            if 'max' in tweet_text or 'verstappen' in tweet_text:\n",
    "                verstappen_count_week += 1\n",
    "    # The final measures are defined as tweet count on race day divided by average daily tweet count in the week around the race\n",
    "    racingdf.loc[racingdf['date'] == racedate,\"tweets_total\"] = total_count_day / (total_count_week / 7)\n",
    "    racingdf.loc[racingdf['date'] == racedate,\"tweets_perez\"] = perez_count_day / (perez_count_week / 7)\n",
    "    racingdf.loc[racingdf['date'] == racedate,\"tweets_verstappen\"] = verstappen_count_day / (verstappen_count_week / 7)\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6d091",
   "metadata": {},
   "source": [
    "### Discussion point: Can you interpret these results? Why is the engagement around Verstappen so large on May 22, July 31, and October 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7062af3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638086b1",
   "metadata": {},
   "source": [
    "We can, of course, do more analysis here. A good starting point is always to use visualization. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'verstappen',\n",
    "             y = 'tweets_verstappen',\n",
    "             data = racingdf,\n",
    "             hue=\"verstappen_out\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d666ec",
   "metadata": {},
   "source": [
    "We can get a more concrete picture by using regression analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = racingdf[['verstappen','perez','verstappen_out','perez_out']]\n",
    "Y = racingdf.tweets_total\n",
    "X = sm.add_constant(X)\n",
    "lm = sm.OLS(Y,X).fit()\n",
    "print (lm.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d098e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = racingdf.tweets_perez\n",
    "lm = sm.OLS(Y,X).fit()\n",
    "print (lm.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = racingdf.tweets_verstappen\n",
    "lm = sm.OLS(Y,X).fit()\n",
    "print (lm.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ab4b5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551b20f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5666cc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fadf64a",
   "metadata": {},
   "source": [
    "**Related Hashtags**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f0b2c",
   "metadata": {},
   "source": [
    "Are people only talking about Red Bull because of Formula 1, or are there other reasons? Answering this may help to answer our first question.\n",
    "\n",
    "We can look directly at the context of the tweets by looking at all its hashtags, without self-processing the text first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fa1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[100]\n",
    "tweet.entities['hashtags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaf19e",
   "metadata": {},
   "source": [
    "There are three hashtags here. We take a look at the third one, since we already knew the first one has to be here (it was our search term after all). Note the structure of hashtags: It's a list of dictionaries, where the key `'text'` gives the hashtag and the key `'indices'` gives the position within the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cf763",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.entities['hashtags'][2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1e55b",
   "metadata": {},
   "source": [
    "Generally, we want to avoid issues with capitalization by using `.lower()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.entities['hashtags'][2]['text'].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf30e7",
   "metadata": {},
   "source": [
    "Let's now get all the hashtags from our tweets (except the redbull hashtags) and convert these into a dataframe, where we count the occurences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attached_tags = [tweet.entities['hashtags'] for tweet in tweets if tweet.entities['hashtags'] != []]\n",
    "attached_tags_cleaned = [hashtag['text'].lower() for tags in attached_tags for hashtag in tags if hashtag['text'].lower() != 'redbull']\n",
    "\n",
    "hashtag_df = pd.DataFrame(attached_tags_cleaned,columns=['hashtag'])\n",
    "hashtag_df = hashtag_df.groupby('hashtag')['hashtag'].count().reset_index(name='count')\n",
    "hashtag_df.sort_values(by='count',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ea3df5",
   "metadata": {},
   "source": [
    "That gives us an initial idea that, yes, at least on race days, this is the biggest topic with which Red Bull causes engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a0076",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc3a08",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d227cb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b83e3e",
   "metadata": {},
   "source": [
    "\n",
    "**Text analysis**\n",
    "\n",
    "We will next use some basic text analytics tools to find out more about what people have to say (and hereby help us find a better answer to Question 2).\n",
    "\n",
    "We can start with the most used words. This gives a sense of how people are perceiving Red Bull. We can easily split tweets into words using `.split()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03088e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[0]\n",
    "tweet.text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f864be",
   "metadata": {},
   "source": [
    "Let's use this to generate a complete list of (lowercase) words (without hashtags):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [tweet.text for tweet in tweets]\n",
    "word_list = [word.lower() for text in text_list for word in text.split() ]\n",
    "word_list = [word.replace('#','') for word in word_list ]\n",
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec6a66",
   "metadata": {},
   "source": [
    "Note: if we got the full tweet text, instead of the first 140 characters, we would have to use `tweet.full_text` instead of `tweet.text` (but the tweets would have to have been collected in the corresponding way)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610cfac",
   "metadata": {},
   "source": [
    "We put these words into a dataframe and count their occurence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(word_list,columns=['word'])\n",
    "word_df = word_df.groupby('word')['word'].count().reset_index(name='count')\n",
    "word_df.sort_values(by='count',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c91600",
   "metadata": {},
   "source": [
    "There is a lot of junk here. One first attempt to clean up this table is to remove all English stopwords (the most common words like \"the\" and \"a\"). Many libraries can do this for us, such as `nltk`. But if we haven't used `nltk` before, we need to download the stopword library first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02929bc2",
   "metadata": {},
   "source": [
    "The English stopwords shouldn't be all too surprising:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af08fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e7361",
   "metadata": {},
   "source": [
    "We can now remove all the (English) stopwords from the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = word_df[~(word_df['word'].isin(nltk.corpus.stopwords.words('english')))]\n",
    "word_df.sort_values(by='count',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858ae1c",
   "metadata": {},
   "source": [
    "*****\n",
    "\n",
    "**Interlude: Sentiment analysis introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469bf47",
   "metadata": {},
   "source": [
    "Beyond counting words, there are fantastic tools out there to analyze sentinments. Usually, we need to start by training a sentiment analyzer. Luckily, `nltk` comes with an in-built pre-trained sentiment analyzer (VADER), purpose-built for analyzing short text on social media (convenient, right?). To use it for the first time, we first have to download its lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffc1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189b70a",
   "metadata": {},
   "source": [
    "Let's see how it works by handing it a short sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d936b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"My outlook on life is fantastic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc791e",
   "metadata": {},
   "source": [
    "The negative, neutral, and positive scores are self-explanatory and numbers here are between $0$ and $1$, with the total adding up to 1. The compound score follows a somewhat complex arithmetic, but it's easy to understand how to use it: it's between $-1$ and $1$, anything $>0$ signifies a positive sentiment, and anything $<0$ signifies a negative sentiment.\n",
    "\n",
    "Can it tell us something about cliché optimists and pessimists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba667c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"The glass is half full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"The glass is half empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8988be",
   "metadata": {},
   "source": [
    "What do you think? Does it make sense to rate the first sentence as neutral and the second one as negative?\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb3427",
   "metadata": {},
   "source": [
    "Now let's apply this simple sentiment analysis to our tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14732732",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets[0]\n",
    "print(tweet.text)\n",
    "sia.polarity_scores(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc1399",
   "metadata": {},
   "source": [
    "We will now go through all tweets, finding the compound score of each tweet and then displaying a histogram of compound scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_scores = []\n",
    "for tweet in tweets:\n",
    "    compound_scores.append(sia.polarity_scores(tweet.text)['compound'])\n",
    "sns.histplot(compound_scores,bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649b23e",
   "metadata": {},
   "source": [
    "Of course, this is just a an initial look at sentiment analysis. You will see some more of this later in the module and in future modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132c9c5",
   "metadata": {},
   "source": [
    "Before that, we want to see what the sentiment analysis can tell us about engagement. Hence, we will analyze the average sentiment of tweets during raceday and add this to our `racingdf` (we first need to add a new column so that we can adjust the individual entries):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa24096",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf['raceday_sentiment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for racedate in racingdf['date']:\n",
    "    sentiment = 0\n",
    "    tweet_count = 0\n",
    "    for tweet in tweets:\n",
    "        if pd.to_datetime(tweet.created_at.date()) == racedate:\n",
    "            sentiment += sia.polarity_scores(tweet.text)['compound']\n",
    "            tweet_count += 1\n",
    "    racingdf.loc[racingdf['date'] == racedate,\"raceday_sentiment\"] = sentiment / tweet_count\n",
    "racingdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50668cf8",
   "metadata": {},
   "source": [
    "### Discussion point: Does this triangulate our previous findings? What about the saying \"all news is good news\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "racingdf['anyone_out'] = racingdf[['perez_out','verstappen_out']].max(axis=1)\n",
    "sns.scatterplot( x = 'date',\n",
    "             y = 'raceday_sentiment',\n",
    "             data = racingdf,\n",
    "            hue=\"anyone_out\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04510ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
